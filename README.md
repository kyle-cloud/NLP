# NLP
Have some NLP-related practice and projects.

[toc]

### 文档目标
这个仓库的目的是为了将我接下来学习 nlp 的路线做一下记录，包括测试代码、练手项目还有自己的学习笔记。

同时也是为了养成一个写文档的好习惯，希望可以更好地梳理知识，并且为大家的浏览带来便利

### 第一部分：分词

#### 1. 总述
1. 分词是自然语言处理的基础，对实验结果有非常大的影响。这是因为中文不想英文那样有空格分隔符，所以需要我们自行分词和断句。
2. 中分分词存在的难点主要是：分词标准、切分歧义、未登录词
3. 目前分词有两种比较普遍的方法：基于词典的规则匹配算法和基于统计的机器学习方法

#### 2. jieba分词练习

（测试代码见 /jieba/practice，顺序记录)

##### 2.1 三种分词模式
1. 精确分词：试图最精确分词，适合文本分析
2. 全模式：扫描出所有词，不能解决歧义
3. 搜索引擎：精确分词+长词再划分，提高recall，适合搜索引擎